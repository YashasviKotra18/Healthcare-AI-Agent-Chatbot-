{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "provenance": [],
      "name": "data preparation"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery, storage\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Ln1nMAp0Yl_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your BigQuery and GCS configurations\n",
        "project_id = \"health-ai-agent-sjsu\"  # Replace with your Google Cloud project ID\n",
        "bq_table_id = \"health-ai-agent-sjsu.transformed_data.all_merged\"  # Replace with your BigQuery table ID\n",
        "bucket_name = \"llm-prepared-data\"  # Replace with your GCS bucket name\n"
      ],
      "metadata": {
        "id": "hPziLK9pYl8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# Initialize BigQuery client\n",
        "bq_client = bigquery.Client(project=project_id)\n",
        "\n",
        "# Query data from BigQuery\n",
        "query = f\"\"\"\n",
        "SELECT Title, Question, Answer\n",
        "FROM `{bq_table_id}`\n",
        "\"\"\"\n",
        "df = bq_client.query(query).to_dataframe()\n",
        "\n",
        "# Prepare data in JSONL format with 'context', 'input', 'output'\n",
        "def prepare_jsonl_entry(row):\n",
        "    return {\n",
        "        \"context\": row[\"Title\"],\n",
        "        \"input\": row[\"Question\"],\n",
        "        \"output\": row[\"Answer\"]\n",
        "    }\n",
        "\n",
        "jsonl_data = df.apply(prepare_jsonl_entry, axis=1).tolist()\n",
        "\n",
        "# Split data into train, validation, and test sets\n",
        "train_data, test_data = train_test_split(jsonl_data, test_size=0.2, random_state=42)\n",
        "valid_data, test_data = train_test_split(test_data, test_size=0.5, random_state=42)  # 10% each for validation and test\n",
        "\n",
        "# Get the current date\n",
        "current_date = datetime.now().strftime(\"%Y%m%d\")\n",
        "\n",
        "# Define file paths with date-stamped filenames\n",
        "train_jsonl_file = f\"llm_training_data_train_{current_date}.jsonl\"\n",
        "valid_jsonl_file = f\"llm_training_data_valid_{current_date}.jsonl\"\n",
        "test_jsonl_file = f\"llm_training_data_test_{current_date}.jsonl\"\n",
        "\n",
        "# Save each split as a JSONL file\n",
        "def save_jsonl(data, filename):\n",
        "    with open(filename, 'w') as f:\n",
        "        for entry in data:\n",
        "            json.dump(entry, f)\n",
        "            f.write('\\n')\n",
        "\n",
        "save_jsonl(train_data, train_jsonl_file)\n",
        "save_jsonl(valid_data, valid_jsonl_file)\n",
        "save_jsonl(test_data, test_jsonl_file)\n",
        "\n",
        "# Initialize GCS client\n",
        "storage_client = storage.Client()\n",
        "\n",
        "# Function to upload a file to GCS under specified folder\n",
        "def upload_file_to_gcs(local_file_path, bucket_name, destination_blob_name):\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(destination_blob_name)\n",
        "    blob.upload_from_filename(local_file_path)\n",
        "    print(f\"File {local_file_path} uploaded to gs://{bucket_name}/{destination_blob_name}\")\n",
        "\n",
        "# Define GCS paths with folder structure and upload files\n",
        "upload_file_to_gcs(train_jsonl_file, bucket_name, f\"llm-prepared-data/train/{train_jsonl_file}\")\n",
        "upload_file_to_gcs(valid_jsonl_file, bucket_name, f\"llm-prepared-data/valid/{valid_jsonl_file}\")\n",
        "upload_file_to_gcs(test_jsonl_file, bucket_name, f\"llm-prepared-data/test/{test_jsonl_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiZ1axkWYAba",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730794489253,
          "user_tz": 480,
          "elapsed": 6238,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "9fa02106-1104-4986-c5fa-44526f80e326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File llm_training_data_train_20241105.jsonl uploaded to gs://llm-prepared-data/llm-prepared-data/train/llm_training_data_train_20241105.jsonl\n",
            "File llm_training_data_valid_20241105.jsonl uploaded to gs://llm-prepared-data/llm-prepared-data/valid/llm_training_data_valid_20241105.jsonl\n",
            "File llm_training_data_test_20241105.jsonl uploaded to gs://llm-prepared-data/llm-prepared-data/test/llm_training_data_test_20241105.jsonl\n"
          ]
        }
      ]
    }
  ]
}